# -*- coding: utf-8 -*-
"""MusicGenreClassification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19SYBw07BQ_q6DnLrrlr8LtPu-PhuG-XA

# MUSIC GENRE CLASSIFICATION USING ANN and CNN
## Name : Aditya Sahani
## College : Indian Institute of Technology, Jodhpur

## Dataset : https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification
"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

!kaggle datasets download -d andradaolteanu/gtzan-dataset-music-genre-classification

import pandas as pd
import numpy as np

import zipfile
zip_ref = zipfile.ZipFile('/content/gtzan-dataset-music-genre-classification.zip', 'r')
zip_ref.extractall('/content')
zip_ref.close()

import tensorflow as tf
from tensorflow import keras
from keras import Sequential
from keras.layers import Dense,BatchNormalization,Dropout

df = pd.read_csv("/content/Data/features_30_sec.csv")

df

df1 = pd.read_csv("/content/Data/features_3_sec.csv")

df1

import librosa

data, sampling_rate = librosa.load('/content/Data/genres_original/blues/blues.00000.wav')

mfccs = librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40)
print(mfccs.shape)

data

import os
import pandas as pd
import librosa
import glob
import matplotlib.pyplot as plt

## displaying the waveform for "Blues" Class

plt.figure(figsize=(12, 4))
plt.plot(data)
plt.title('Waveform')
plt.xlabel('Sample')
plt.ylabel('Amplitude')
plt.show()

# Displaying the waveform for the "Classical" Class
data, sampling_rate = librosa.load('/content/Data/genres_original/classical/classical.00004.wav')

# Plot the waveform
plt.figure(figsize=(12, 4))
plt.plot(data)
plt.title('Waveform')
plt.xlabel('Sample')
plt.ylabel('Amplitude')
plt.show()

data.shape

import IPython.display as ipd
import librosa
import librosa.display

ipd.Audio("/content/Data/genres_original/classical/classical.00004.wav")

## function to extract the coefficients from the audio array
def features_extractor(file_name):
    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')
    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)
    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)

    return mfccs_scaled_features

import os
import librosa


parent_dir = '/content/Data'

genres_dir = os.path.join(parent_dir, 'genres_original')

# List of class names
class_names = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']

# Dictionary to store audio data classwise
audio_data = {}

# Fixed duration for loading each audio file (in seconds)
fixed_duration = 2

# Loop through each class folder
for class_name in class_names:
    # Create an empty list to store audio data for the current class
    class_audio_data = []

    # Define the path to the current class folder
    class_dir = os.path.join(genres_dir, class_name)

    # Loop through each audio file in the class folder
    for filename in os.listdir(class_dir):
        # Check if the file is a .wav file
        if filename.endswith('.wav'):
            # Load the audio file using librosa with fixed duration
            file_path = os.path.join(class_dir, filename)
            try:

                data = features_extractor(file_path)
                class_audio_data.append(data)
            except Exception as e:
                print(f"Error loading audio file: {file_path}. Error: {e}")

    # Store the audio data for the current class in the dictionary
    audio_data[class_name] = class_audio_data

classes = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']

import pandas as pd


class_dict = audio_data

# Initialize an empty list to store dictionaries
data = []

# Iterate through the dictionary
for label, arrays in class_dict.items():
    for array in arrays:
        data.append({'class': label, 'array': array})

# Convert the list of dictionaries into a DataFrame
df = pd.DataFrame(data)

df.head()

df.shape

shuffled_df = df.sample(frac=1, random_state=42)  # Set random_state for reproducibility
shuffled_df.reset_index(drop=True, inplace=True)  # Reset the index of the shuffled DataFrame

shuffled_df.shape

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(shuffled_df["class"])

y.shape

X = shuffled_df.drop(columns=["class"])

X = X.values

X.shape

shuffled_df.head()

import numpy as np


array_list = []

for index, row in shuffled_df.iterrows():
    array = row[1]  # Extract the array from the row
    array_list.append(array)

# Convert the list of arrays into a 2D NumPy array
result_array_2d = np.vstack(array_list)

# Print the 2D array
print(result_array_2d)

result_array_2d.shape

from sklearn.preprocessing import StandardScaler
ss = StandardScaler()
result_array_2d = ss.fit_transform(result_array_2d)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(result_array_2d, y, test_size = 0.2, random_state=42)

from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
import xgboost as xgb

## SupportVectorMachine Classifier
dtc = SVC(kernel="rbf")

dtc.fit(X_train, y_train)

y_pred = dtc.predict(X_test)

from sklearn.metrics import accuracy_score

accuracy_score(y_test, y_pred)

## RandomForest Classifier
from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(n_estimators=100, max_depth=30)

rfc.fit(X_train, y_train)
y_pred = rfc.predict(X_test)
accuracy_score(y_test, y_pred)

## XGBoost Classifier
import xgboost as xgb
xg = xgb.XGBClassifier(n_estimators=50)
xg.fit(X_train, y_train)
y_pred = xg.predict(X_test)
accuracy_score(y_test, y_pred)

import tensorflow as tf
from tensorflow import keras
from keras import Sequential
from keras.layers import Dense

model = Sequential()

model.add(BatchNormalization())
model.add(Dense(128, activation="relu", input_dim=X_train.shape[1]))
# model.add(BatchNormalization())

model.add(Dropout(0.2))
model.add(Dense(64, activation="relu"))
# model.add(BatchNormalization())

model.add(Dropout(0.2))
model.add(Dense(32, activation="relu"))
# model.add(BatchNormalization())

model.add(Dropout(0.2))
model.add(Dense(16, activation="relu"))

model.add(Dropout(0.1))
model.add(Dense(10, activation="softmax"))

model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

history = model.fit(X_train, y_train, epochs=50, validation_data=[X_test, y_test])

"""# Convolutional Neural Network (CNN)
## Training CNN on Mel Spectrogram of Audio file

### Mel Spectrogram : A Mel spectrogram is a visual representation of the spectrum of a sound signal, where the frequency axis is converted from a linear scale (Hertz) to the mel scale, which approximates the human auditory system's perception of pitch. It displays the intensity of different frequencies of a signal over time, often used in audio processing tasks such as speech recognition and music analysis.
"""

import tensorflow as tf
from tensorflow import keras
from keras import Sequential
from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout

# Load audio file
audio_file = '/content/Data/genres_original/blues/blues.00000.wav'
y, sr = librosa.load(audio_file)

# Compute the Mel spectrogram
mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)

# Display the Mel spectrogram
plt.figure(figsize=(10, 4))
librosa.display.specshow(librosa.power_to_db(mel_spectrogram, ref=np.max), sr=sr, x_axis='time', y_axis='mel')
plt.colorbar(format='%+2.0f dB')
plt.title('Mel Spectrogram')
plt.show()

model = Sequential()

model.add(Conv2D(64, kernel_size=(3,3), padding="valid", activation="relu", input_shape=(256,256,3)))
model.add(BatchNormalization())
# model.add(MaxPooling2D(pool_size = (2,2), strides=2, padding="valid"))

model.add(Conv2D(32, kernel_size=(3,3), padding="valid", activation="relu"))
model.add(BatchNormalization())
# model.add(MaxPooling2D(pool_size = (2,2), strides=2, padding="valid"))

model.add(Conv2D(16, kernel_size=(3,3), padding="valid", activation="relu"))
model.add(BatchNormalization())
# model.add(MaxPooling2D(pool_size = (2,2), strides=2, padding="valid"))

model.add(Flatten())

model.add(Dense(64, activation="relu"))
model.add(Dropout(0.1))
model.add(Dense(32, activation="relu"))
model.add(Dropout(0.1))
model.add(Dense(16, activation="relu"))
model.add(Dropout(0.1))


model.add(Dense(10, activation="softmax"))

model.summary()

train_ds = keras.utils.image_dataset_from_directory(
    directory = '/content/Data/images_original',
    labels='inferred',
    label_mode = 'int',
    batch_size=32,
    image_size=(256,256)
)

def process(image,label):
    image = tf.cast(image/255. ,tf.float32)
    return image,label

train_ds = train_ds.map(process)

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

history = model.fit(train_ds,epochs=10, batch_size=32)

## Getting an accuracy of : {}

"""# Artificial Neural Network (ANN)"""

## reading the data
import pandas as pd
from sklearn.preprocessing import LabelEncoder
df = pd.read_csv('/content/Data/features_3_sec.csv')
df.head()

df.info()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

x = df[["label", "tempo"]]  ## box-plot of the Beats/ Minute

fig, ax = plt.subplots(figsize=(15, 6));
sns.boxplot(x = "label", y = "tempo", data = x, palette = 'husl', legend=False);

plt.title('BPM Boxplot for Genres', fontsize = 20)
plt.xticks(fontsize = 14)
plt.yticks(fontsize = 10);
plt.xlabel("Genre", fontsize = 15)
plt.ylabel("BPM", fontsize = 15)

data = df.drop(columns=["filename", "length"])

X = data.drop(columns=["label"]).values

le = LabelEncoder()

y = le.fit_transform(data["label"])

# y = data["label"].values

from sklearn.model_selection import train_test_split

X_train,X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)

## writing the model

model = Sequential()

model.add(BatchNormalization())
model.add(Dense(512, activation="relu", input_dim=X.shape[1]))
# model.add(BatchNormalization())
# model.add(Dropout(0.2))
model.add(Dense(256, activation="relu"))
# model.add(BatchNormalization())
# model.add(Dropout(0.2))
model.add(Dense(128, activation="relu"))
# model.add(BatchNormalization())
# model.add(Dropout(0.2))
model.add(Dense(64, activation="relu"))

# model.add(Dropout(0.2))
model.add(Dense(10, activation="softmax"))

model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

callback  = keras.callbacks.EarlyStopping(
    monitor="val_loss",
    min_delta=0,
    patience=0,
    verbose=0,
    mode="auto",
    baseline=None,
    restore_best_weights=False,
    start_from_epoch=0,
)

history = model.fit(X_train, y_train, epochs=20, validation_data=[X_test, y_test])

y_pred = model.predict(X_test)

y_pred

y_test

accuracy_score(y_test, y_pred)

